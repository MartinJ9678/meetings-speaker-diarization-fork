{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eaccec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:14:44.619085Z",
     "start_time": "2021-05-26T12:14:44.596691Z"
    }
   },
   "source": [
    "# Pyannote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522f227",
   "metadata": {},
   "source": [
    "### Import from develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/pyannote/pyannote-audio@062bd7bd9a315953b1420500b5061f896c68b4ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e74c04d",
   "metadata": {},
   "source": [
    "### Import from master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430a1a6",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7f917",
   "metadata": {},
   "source": [
    "![title](https://github.com/pyannote/pyannote-audio/raw/master/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c33eca",
   "metadata": {},
   "source": [
    "# dia_ami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0496396",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ef864",
   "metadata": {},
   "source": [
    "- Model pytorch dia_ami\n",
    "- Train sur le dataset AMI (70h de meetings annot√©s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8f36a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:14:28.820225Z",
     "start_time": "2021-05-26T12:14:28.136716Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "/Users/loicsaillant/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/embedding/approaches/arcface_loss.py:170: FutureWarning: The 's' parameter is deprecated in favor of 'scale', and will be removed in a future release\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia_ami');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29261a36",
   "metadata": {},
   "source": [
    "## Test avec Doctolib.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c20375",
   "metadata": {},
   "source": [
    "Fichier audio issu d'une vid√©o avec 3 speakers\n",
    "- 2 speakers qui parlent la plupart du temps\n",
    "- 1 speaker qui parle tr√®s peu\n",
    "- musique au d√©but\n",
    "- FR üá´üá∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42124dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:43:06.443134Z",
     "start_time": "2021-05-26T12:40:01.579831Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/doctolib.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec23e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:43:06.457940Z",
     "start_time": "2021-05-26T12:43:06.448189Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/doctolib_ami.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d4dfae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:44:40.838430Z",
     "start_time": "2021-05-26T12:44:40.820118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.4s and t=0.9s.\n",
      "Speaker \"22\" speaks between t=0.9s and t=1.6s.\n",
      "Speaker \"A\" speaks between t=1.6s and t=12.4s.\n",
      "Speaker \"B\" speaks between t=12.4s and t=14.0s.\n",
      "Speaker \"A\" speaks between t=14.0s and t=38.4s.\n",
      "Speaker \"B\" speaks between t=38.4s and t=53.5s.\n",
      "Speaker \"A\" speaks between t=53.5s and t=55.8s.\n",
      "Speaker \"B\" speaks between t=55.8s and t=97.2s.\n",
      "Speaker \"A\" speaks between t=97.2s and t=148.2s.\n",
      "Speaker \"B\" speaks between t=148.2s and t=162.3s.\n",
      "Speaker \"A\" speaks between t=162.3s and t=163.3s.\n",
      "Speaker \"B\" speaks between t=163.3s and t=168.3s.\n",
      "Speaker \"A\" speaks between t=168.3s and t=169.0s.\n",
      "Speaker \"B\" speaks between t=169.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39bf9a",
   "metadata": {},
   "source": [
    "### Remarques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92975f",
   "metadata": {},
   "source": [
    "- Diarization pr√©cise\n",
    "- La musique au d√©but est d√©t√©ct√©e comme de la SAD ü§î\n",
    "- Speaker 22 ü§∑üèª‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d3511",
   "metadata": {},
   "source": [
    "## Test avec martin.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b740c25",
   "metadata": {},
   "source": [
    "- Interview tele \n",
    "- 2 personnes\n",
    "- EN üá∫üá∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd1727b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.784310Z",
     "start_time": "2021-05-26T12:45:08.584426Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization_martin = pipeline({'audio': 'data/martin.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9480e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.793044Z",
     "start_time": "2021-05-26T12:46:44.788674Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin_ami.rttm', 'w') as f:\n",
    "    diarization_martin.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24ffdf2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.798762Z",
     "start_time": "2021-05-26T12:46:44.795318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.0s and t=5.8s.\n",
      "Speaker \"9\" speaks between t=5.8s and t=6.5s.\n",
      "Speaker \"A\" speaks between t=6.5s and t=16.9s.\n",
      "Speaker \"A\" speaks between t=18.3s and t=22.5s.\n",
      "Speaker \"13\" speaks between t=22.5s and t=23.2s.\n",
      "Speaker \"A\" speaks between t=23.2s and t=110.4s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization_martin.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294fc38",
   "metadata": {},
   "source": [
    "# dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463b10a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e870b4a",
   "metadata": {},
   "source": [
    "- Model pytorch dia\n",
    "- Train sur VoxCeleb1.custom.trn ‚ãÉ VoxCeleb2.trn ‚ãÉ DIHARD.custom.tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb9e64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:52:42.855607Z",
     "start_time": "2021-05-26T12:52:41.729283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "/Users/loicsaillant/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/embedding/approaches/arcface_loss.py:170: FutureWarning: The 's' parameter is deprecated in favor of 'scale', and will be removed in a future release\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/loicsaillant/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/pretrained.py:156: UserWarning: Model was trained with 4s chunks and is applied on 2s chunks. This might lead to sub-optimal results.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d9e12",
   "metadata": {},
   "source": [
    "## doctolib.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d6d861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:09:43.893418Z",
     "start_time": "2021-05-26T13:01:16.698914Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/doctolib.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f3764b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:09:43.918404Z",
     "start_time": "2021-05-26T13:09:43.905988Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/doctolib.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a7c67b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:09:43.925574Z",
     "start_time": "2021-05-26T13:09:43.920732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.6s and t=0.8s.\n",
      "Speaker \"B\" speaks between t=1.0s and t=2.3s.\n",
      "Speaker \"A\" speaks between t=2.3s and t=4.3s.\n",
      "Speaker \"A\" speaks between t=4.8s and t=5.3s.\n",
      "Speaker \"A\" speaks between t=5.6s and t=5.8s.\n",
      "Speaker \"A\" speaks between t=6.1s and t=9.8s.\n",
      "Speaker \"A\" speaks between t=10.2s and t=11.6s.\n",
      "Speaker \"A\" speaks between t=11.9s and t=15.5s.\n",
      "Speaker \"A\" speaks between t=15.9s and t=18.8s.\n",
      "Speaker \"A\" speaks between t=19.5s and t=20.4s.\n",
      "Speaker \"A\" speaks between t=20.8s and t=24.6s.\n",
      "Speaker \"A\" speaks between t=24.8s and t=25.1s.\n",
      "Speaker \"A\" speaks between t=25.3s and t=31.0s.\n",
      "Speaker \"A\" speaks between t=31.4s and t=34.8s.\n",
      "Speaker \"B\" speaks between t=35.0s and t=39.2s.\n",
      "Speaker \"B\" speaks between t=39.6s and t=46.4s.\n",
      "Speaker \"B\" speaks between t=46.9s and t=49.4s.\n",
      "Speaker \"B\" speaks between t=49.6s and t=52.7s.\n",
      "Speaker \"A\" speaks between t=52.7s and t=54.3s.\n",
      "Speaker \"A\" speaks between t=54.6s and t=55.1s.\n",
      "Speaker \"B\" speaks between t=55.1s and t=56.7s.\n",
      "Speaker \"B\" speaks between t=56.8s and t=59.0s.\n",
      "Speaker \"B\" speaks between t=59.4s and t=65.5s.\n",
      "Speaker \"B\" speaks between t=65.8s and t=71.7s.\n",
      "Speaker \"B\" speaks between t=72.0s and t=73.9s.\n",
      "Speaker \"B\" speaks between t=74.4s and t=78.6s.\n",
      "Speaker \"B\" speaks between t=79.1s and t=83.1s.\n",
      "Speaker \"B\" speaks between t=83.7s and t=84.8s.\n",
      "Speaker \"B\" speaks between t=85.4s and t=91.2s.\n",
      "Speaker \"B\" speaks between t=91.6s and t=95.9s.\n",
      "Speaker \"A\" speaks between t=95.9s and t=100.6s.\n",
      "Speaker \"A\" speaks between t=101.0s and t=105.5s.\n",
      "Speaker \"A\" speaks between t=105.8s and t=107.8s.\n",
      "Speaker \"A\" speaks between t=108.1s and t=108.8s.\n",
      "Speaker \"A\" speaks between t=109.2s and t=117.8s.\n",
      "Speaker \"A\" speaks between t=118.3s and t=122.3s.\n",
      "Speaker \"A\" speaks between t=122.5s and t=125.4s.\n",
      "Speaker \"A\" speaks between t=125.8s and t=129.2s.\n",
      "Speaker \"A\" speaks between t=129.6s and t=132.5s.\n",
      "Speaker \"A\" speaks between t=132.8s and t=147.5s.\n",
      "Speaker \"B\" speaks between t=147.7s and t=154.5s.\n",
      "Speaker \"B\" speaks between t=154.9s and t=157.4s.\n",
      "Speaker \"B\" speaks between t=157.7s and t=178.2s.\n",
      "Speaker \"B\" speaks between t=178.5s and t=179.6s.\n",
      "Speaker \"B\" speaks between t=179.9s and t=181.8s.\n",
      "Speaker \"B\" speaks between t=182.1s and t=184.1s.\n",
      "Speaker \"B\" speaks between t=184.4s and t=189.3s.\n",
      "Speaker \"B\" speaks between t=189.7s and t=193.1s.\n",
      "Speaker \"B\" speaks between t=193.7s and t=194.7s.\n",
      "Speaker \"B\" speaks between t=195.2s and t=200.1s.\n",
      "Speaker \"B\" speaks between t=200.4s and t=206.7s.\n",
      "Speaker \"B\" speaks between t=207.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005113d",
   "metadata": {},
   "source": [
    "## martin.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76275ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:16:19.565116Z",
     "start_time": "2021-05-26T13:11:59.262505Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/martin.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5188217a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:16:19.588014Z",
     "start_time": "2021-05-26T13:16:19.570897Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc1a6c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:16:19.598611Z",
     "start_time": "2021-05-26T13:16:19.590285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"B\" speaks between t=0.0s and t=1.1s.\n",
      "Speaker \"B\" speaks between t=1.8s and t=4.3s.\n",
      "Speaker \"B\" speaks between t=4.5s and t=7.1s.\n",
      "Speaker \"B\" speaks between t=7.8s and t=9.1s.\n",
      "Speaker \"B\" speaks between t=9.4s and t=11.0s.\n",
      "Speaker \"B\" speaks between t=11.2s and t=12.9s.\n",
      "Speaker \"B\" speaks between t=13.4s and t=14.6s.\n",
      "Speaker \"B\" speaks between t=15.2s and t=15.6s.\n",
      "Speaker \"B\" speaks between t=16.1s and t=16.5s.\n",
      "Speaker \"B\" speaks between t=18.4s and t=19.5s.\n",
      "Speaker \"B\" speaks between t=20.0s and t=23.7s.\n",
      "Speaker \"A\" speaks between t=24.4s and t=26.6s.\n",
      "Speaker \"A\" speaks between t=27.4s and t=31.4s.\n",
      "Speaker \"B\" speaks between t=31.9s and t=34.3s.\n",
      "Speaker \"B\" speaks between t=34.5s and t=36.7s.\n",
      "Speaker \"B\" speaks between t=37.7s and t=38.6s.\n",
      "Speaker \"A\" speaks between t=38.6s and t=42.4s.\n",
      "Speaker \"A\" speaks between t=42.8s and t=45.0s.\n",
      "Speaker \"A\" speaks between t=46.1s and t=51.0s.\n",
      "Speaker \"A\" speaks between t=51.9s and t=54.9s.\n",
      "Speaker \"A\" speaks between t=55.6s and t=56.5s.\n",
      "Speaker \"A\" speaks between t=57.3s and t=60.7s.\n",
      "Speaker \"A\" speaks between t=61.7s and t=63.2s.\n",
      "Speaker \"A\" speaks between t=63.6s and t=65.3s.\n",
      "Speaker \"A\" speaks between t=65.9s and t=66.9s.\n",
      "Speaker \"A\" speaks between t=67.4s and t=68.1s.\n",
      "Speaker \"A\" speaks between t=69.1s and t=70.8s.\n",
      "Speaker \"A\" speaks between t=71.6s and t=73.0s.\n",
      "Speaker \"A\" speaks between t=74.4s and t=75.6s.\n",
      "Speaker \"A\" speaks between t=76.0s and t=77.2s.\n",
      "Speaker \"B\" speaks between t=77.7s and t=78.6s.\n",
      "Speaker \"A\" speaks between t=79.7s and t=80.0s.\n",
      "Speaker \"A\" speaks between t=80.3s and t=83.5s.\n",
      "Speaker \"A\" speaks between t=83.8s and t=89.1s.\n",
      "Speaker \"A\" speaks between t=89.5s and t=92.7s.\n",
      "Speaker \"B\" speaks between t=92.7s and t=93.3s.\n",
      "Speaker \"A\" speaks between t=93.8s and t=97.7s.\n",
      "Speaker \"A\" speaks between t=98.6s and t=102.8s.\n",
      "Speaker \"A\" speaks between t=103.5s and t=104.1s.\n",
      "Speaker \"A\" speaks between t=104.8s and t=107.4s.\n",
      "Speaker \"A\" speaks between t=108.5s and t=110.1s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfc4e5",
   "metadata": {},
   "source": [
    "### Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1374a582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:30:13.857465Z",
     "start_time": "2021-05-26T13:30:13.853823Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyannote.database.util import load_rttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0da3815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:44:37.576165Z",
     "start_time": "2021-05-26T13:44:37.373725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x1787184f0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = load_rttm('outputs/martin.rttm')\n",
    "pred['<NA>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57461e5",
   "metadata": {},
   "source": [
    "## martin2.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da69a673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:30:13.822347Z",
     "start_time": "2021-05-26T13:22:25.065690Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/martin2.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd3653ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:30:13.838899Z",
     "start_time": "2021-05-26T13:30:13.829460Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin2.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58fd68a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:30:13.850945Z",
     "start_time": "2021-05-26T13:30:13.842207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"B\" speaks between t=0.4s and t=3.1s.\n",
      "Speaker \"B\" speaks between t=3.4s and t=5.5s.\n",
      "Speaker \"B\" speaks between t=5.9s and t=11.6s.\n",
      "Speaker \"A\" speaks between t=11.9s and t=13.7s.\n",
      "Speaker \"A\" speaks between t=14.0s and t=17.6s.\n",
      "Speaker \"B\" speaks between t=18.0s and t=21.0s.\n",
      "Speaker \"A\" speaks between t=21.0s and t=25.4s.\n",
      "Speaker \"A\" speaks between t=25.7s and t=31.2s.\n",
      "Speaker \"B\" speaks between t=31.4s and t=34.3s.\n",
      "Speaker \"B\" speaks between t=34.8s and t=37.4s.\n",
      "Speaker \"A\" speaks between t=37.4s and t=41.3s.\n",
      "Speaker \"A\" speaks between t=41.6s and t=44.4s.\n",
      "Speaker \"B\" speaks between t=44.7s and t=46.7s.\n",
      "Speaker \"B\" speaks between t=47.2s and t=48.3s.\n",
      "Speaker \"B\" speaks between t=48.9s and t=52.4s.\n",
      "Speaker \"A\" speaks between t=52.4s and t=56.1s.\n",
      "Speaker \"B\" speaks between t=56.5s and t=57.7s.\n",
      "Speaker \"A\" speaks between t=58.0s and t=61.7s.\n",
      "Speaker \"B\" speaks between t=62.1s and t=64.8s.\n",
      "Speaker \"B\" speaks between t=65.3s and t=67.4s.\n",
      "Speaker \"A\" speaks between t=67.7s and t=69.6s.\n",
      "Speaker \"A\" speaks between t=69.9s and t=73.6s.\n",
      "Speaker \"B\" speaks between t=74.0s and t=75.7s.\n",
      "Speaker \"B\" speaks between t=76.0s and t=78.0s.\n",
      "Speaker \"A\" speaks between t=78.4s and t=83.1s.\n",
      "Speaker \"A\" speaks between t=83.4s and t=84.4s.\n",
      "Speaker \"B\" speaks between t=84.7s and t=86.3s.\n",
      "Speaker \"B\" speaks between t=86.5s and t=89.8s.\n",
      "Speaker \"A\" speaks between t=89.8s and t=92.6s.\n",
      "Speaker \"A\" speaks between t=93.0s and t=95.6s.\n",
      "Speaker \"B\" speaks between t=95.9s and t=98.6s.\n",
      "Speaker \"A\" speaks between t=98.6s and t=104.3s.\n",
      "Speaker \"A\" speaks between t=104.6s and t=107.9s.\n",
      "Speaker \"B\" speaks between t=107.9s and t=110.5s.\n",
      "Speaker \"A\" speaks between t=110.7s and t=112.1s.\n",
      "Speaker \"A\" speaks between t=112.4s and t=114.4s.\n",
      "Speaker \"A\" speaks between t=114.8s and t=116.2s.\n",
      "Speaker \"B\" speaks between t=116.7s and t=119.0s.\n",
      "Speaker \"A\" speaks between t=119.4s and t=122.7s.\n",
      "Speaker \"A\" speaks between t=123.0s and t=124.2s.\n",
      "Speaker \"A\" speaks between t=124.4s and t=125.1s.\n",
      "Speaker \"A\" speaks between t=125.3s and t=127.2s.\n",
      "Speaker \"B\" speaks between t=127.6s and t=130.8s.\n",
      "Speaker \"B\" speaks between t=131.1s and t=133.0s.\n",
      "Speaker \"A\" speaks between t=133.4s and t=136.7s.\n",
      "Speaker \"B\" speaks between t=137.0s and t=141.5s.\n",
      "Speaker \"A\" speaks between t=141.8s and t=144.3s.\n",
      "Speaker \"B\" speaks between t=145.1s and t=149.9s.\n",
      "Speaker \"B\" speaks between t=150.4s and t=151.7s.\n",
      "Speaker \"A\" speaks between t=152.1s and t=154.2s.\n",
      "Speaker \"A\" speaks between t=154.5s and t=155.1s.\n",
      "Speaker \"B\" speaks between t=155.4s and t=156.9s.\n",
      "Speaker \"A\" speaks between t=157.5s and t=160.5s.\n",
      "Speaker \"B\" speaks between t=160.8s and t=163.1s.\n",
      "Speaker \"A\" speaks between t=163.4s and t=165.3s.\n",
      "Speaker \"A\" speaks between t=165.5s and t=168.6s.\n",
      "Speaker \"B\" speaks between t=168.9s and t=170.7s.\n",
      "Speaker \"A\" speaks between t=170.9s and t=172.4s.\n",
      "Speaker \"B\" speaks between t=172.4s and t=175.0s.\n",
      "Speaker \"A\" speaks between t=175.2s and t=177.0s.\n",
      "Speaker \"A\" speaks between t=177.2s and t=180.1s.\n",
      "Speaker \"A\" speaks between t=180.2s and t=182.9s.\n",
      "Speaker \"A\" speaks between t=183.2s and t=185.4s.\n",
      "Speaker \"B\" speaks between t=185.9s and t=188.4s.\n",
      "Speaker \"A\" speaks between t=188.4s and t=197.4s.\n",
      "Speaker \"A\" speaks between t=197.7s and t=200.1s.\n",
      "Speaker \"B\" speaks between t=200.3s and t=203.7s.\n",
      "Speaker \"A\" speaks between t=203.7s and t=208.1s.\n",
      "Speaker \"A\" speaks between t=208.7s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e2e3c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:38:32.589897Z",
     "start_time": "2021-05-26T13:38:32.585753Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyannote.core import Segment, notebook\n",
    "# make notebook visualization zoom on 600s < t < 660s time range\n",
    "EXCERPT = Segment(0, 220)\n",
    "notebook.crop = EXCERPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c41b0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:39:44.715143Z",
     "start_time": "2021-05-26T13:39:44.412251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x1784803a0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth = load_rttm('outputs/groundtruth/martin2_gt.rttm')\n",
    "groundtruth = groundtruth['121-127105']\n",
    "groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e842b869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:40:26.278849Z",
     "start_time": "2021-05-26T13:40:26.209496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false alarm': 3.3459999999999868,\n",
       " 'confusion': 7.154999999999987,\n",
       " 'correct': 178.07800000000003,\n",
       " 'total': 192.75000000000003,\n",
       " 'missed detection': 7.516999999999999,\n",
       " 'diarization error rate': 0.09347859922178972}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "pred = load_rttm('outputs/martin2.rttm')['<NA>']\n",
    "\n",
    "metric = DiarizationErrorRate()\n",
    "der = metric(groundtruth, pred,detailed=True)\n",
    "der"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17706db0",
   "metadata": {},
   "source": [
    "## Speaker activity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3870fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:34:32.587236Z",
     "start_time": "2021-05-26T10:26:08.337265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is speech between t=0.6s and t=0.8s.\n",
      "There is speech between t=1.0s and t=2.3s.\n",
      "There is speech between t=2.3s and t=4.3s.\n",
      "There is speech between t=4.8s and t=5.3s.\n",
      "There is speech between t=5.6s and t=5.8s.\n",
      "There is speech between t=6.1s and t=9.8s.\n",
      "There is speech between t=10.2s and t=11.6s.\n",
      "There is speech between t=11.9s and t=15.5s.\n",
      "There is speech between t=15.9s and t=18.8s.\n",
      "There is speech between t=19.5s and t=20.4s.\n",
      "There is speech between t=20.8s and t=24.6s.\n",
      "There is speech between t=24.8s and t=25.1s.\n",
      "There is speech between t=25.3s and t=31.0s.\n",
      "There is speech between t=31.4s and t=34.8s.\n",
      "There is speech between t=35.0s and t=39.2s.\n",
      "There is speech between t=39.6s and t=46.4s.\n",
      "There is speech between t=46.9s and t=49.4s.\n",
      "There is speech between t=49.6s and t=52.7s.\n",
      "There is speech between t=52.7s and t=54.3s.\n",
      "There is speech between t=54.6s and t=55.1s.\n",
      "There is speech between t=55.1s and t=56.7s.\n",
      "There is speech between t=56.8s and t=59.0s.\n",
      "There is speech between t=59.4s and t=65.5s.\n",
      "There is speech between t=65.8s and t=71.7s.\n",
      "There is speech between t=72.0s and t=73.9s.\n",
      "There is speech between t=74.4s and t=78.6s.\n",
      "There is speech between t=79.1s and t=83.1s.\n",
      "There is speech between t=83.7s and t=84.8s.\n",
      "There is speech between t=85.4s and t=91.2s.\n",
      "There is speech between t=91.6s and t=95.9s.\n",
      "There is speech between t=95.9s and t=100.6s.\n",
      "There is speech between t=101.0s and t=105.5s.\n",
      "There is speech between t=105.8s and t=107.8s.\n",
      "There is speech between t=108.1s and t=108.8s.\n",
      "There is speech between t=109.2s and t=117.8s.\n",
      "There is speech between t=118.3s and t=122.3s.\n",
      "There is speech between t=122.5s and t=125.4s.\n",
      "There is speech between t=125.8s and t=129.2s.\n",
      "There is speech between t=129.6s and t=132.5s.\n",
      "There is speech between t=132.8s and t=147.5s.\n",
      "There is speech between t=147.7s and t=154.5s.\n",
      "There is speech between t=154.9s and t=157.4s.\n",
      "There is speech between t=157.7s and t=178.2s.\n",
      "There is speech between t=178.5s and t=179.6s.\n",
      "There is speech between t=179.9s and t=181.8s.\n",
      "There is speech between t=182.1s and t=184.1s.\n",
      "There is speech between t=184.4s and t=189.3s.\n",
      "There is speech between t=189.7s and t=193.1s.\n",
      "There is speech between t=193.7s and t=194.7s.\n",
      "There is speech between t=195.2s and t=200.1s.\n",
      "There is speech between t=200.4s and t=206.7s.\n",
      "There is speech between t=207.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "pipeline_sad = torch.hub.load('pyannote/pyannote-audio', 'sad', pipeline=True)\n",
    "\n",
    "# apply speech activity detection pipeline on your audio file\n",
    "speech_activity_detection = pipeline({'audio': 'data/doctolib.wav'})\n",
    "\n",
    "# dump result to disk using RTTM format\n",
    "# with open('/path/to/your/audio.sad.rttm', 'w') as f:\n",
    "#     speech_activity_detection.write_rttm(f)\n",
    "\n",
    "for speech_region in speech_activity_detection.get_timeline():\n",
    "    print(f'There is speech between t={speech_region.start:.1f}s and t={speech_region.end:.1f}s.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
