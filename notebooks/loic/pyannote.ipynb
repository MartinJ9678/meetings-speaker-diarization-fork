{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eaccec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:14:44.619085Z",
     "start_time": "2021-05-26T12:14:44.596691Z"
    }
   },
   "source": [
    "# Pyannote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522f227",
   "metadata": {},
   "source": [
    "### Import from develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94bd2f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:12:30.083856Z",
     "start_time": "2021-05-26T15:11:03.271357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pyannote/pyannote-audio@062bd7bd9a315953b1420500b5061f896c68b4ab\n",
      "  Cloning https://github.com/pyannote/pyannote-audio (to revision 062bd7bd9a315953b1420500b5061f896c68b4ab) to /private/var/folders/bl/t479nsz11y1gqdx_gntwzh8m0000gn/T/pip-req-build-x3c8_ocz\n",
      "  Running command git clone -q https://github.com/pyannote/pyannote-audio /private/var/folders/bl/t479nsz11y1gqdx_gntwzh8m0000gn/T/pip-req-build-x3c8_ocz\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pyannote/pyannote-audio@062bd7bd9a315953b1420500b5061f896c68b4ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e74c04d",
   "metadata": {},
   "source": [
    "### Import from master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4dc87d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:13:02.626065Z",
     "start_time": "2021-05-26T15:12:33.637880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote.audio-1.1.2-py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=2.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (0.24.2)\n",
      "Collecting librosa>=0.8.0\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 901 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=6.2.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (8.2.0)\n",
      "Requirement already satisfied: pandas>=0.18.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (1.2.3)\n",
      "Collecting pyannote.pipeline<2.0.0,>=1.5.2\n",
      "  Downloading pyannote.pipeline-1.5.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (4.2.1)\n",
      "Requirement already satisfied: pyannote.database>=4.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (4.1)\n",
      "Requirement already satisfied: pyYAML>=3.12 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (5.4.1)\n",
      "Requirement already satisfied: pyannote.metrics>=2.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (3.0.1)\n",
      "Collecting sortedcollections>=1.0.1\n",
      "  Downloading sortedcollections-2.1.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pescador>=2.1.0\n",
      "  Downloading pescador-2.1.0.tar.gz (20 kB)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (0.10.3.post1)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (4.59.0)\n",
      "Requirement already satisfied: pyannote.core>=4.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.audio) (4.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from librosa>=0.8.0->pyannote.audio) (1.6.2)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 546 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from librosa>=0.8.0->pyannote.audio) (1.0.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from librosa>=0.8.0->pyannote.audio) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from librosa>=0.8.0->pyannote.audio) (1.18.5)\n",
      "Collecting numba>=0.43.0\n",
      "  Downloading numba-0.53.1-cp38-cp38-macosx_10_14_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from librosa>=0.8.0->pyannote.audio) (20.9)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp38-cp38-macosx_10_9_x86_64.whl (18.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.5 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.8.0->pyannote.audio) (49.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from packaging>=20.0->librosa>=0.8.0->pyannote.audio) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pandas>=0.18.0->pyannote.audio) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pandas>=0.18.0->pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: six>=1.8 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pescador>=2.1.0->pyannote.audio) (1.15.0)\n",
      "Requirement already satisfied: pyzmq>=15.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pescador>=2.1.0->pyannote.audio) (22.0.3)\n",
      "Requirement already satisfied: appdirs in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.8.0->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: requests in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.8.0->pyannote.audio) (2.25.1)\n",
      "Requirement already satisfied: simplejson>=3.8.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.core>=4.1->pyannote.audio) (3.17.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.core>=4.1->pyannote.audio) (3.7.4.3)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.core>=4.1->pyannote.audio) (3.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from matplotlib>=2.0.0->pyannote.core>=4.1->pyannote.audio) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from matplotlib>=2.0.0->pyannote.core>=4.1->pyannote.audio) (1.3.1)\n",
      "Requirement already satisfied: typer[all]>=0.2.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.database>=4.0->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: sympy>=1.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.metrics>=2.3->pyannote.audio) (1.8)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.metrics>=2.3->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyannote.metrics>=2.3->pyannote.audio) (0.8.9)\n",
      "Collecting optuna>=1.4\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock>=3.0.10\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: alembic in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.4.15)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from scikit-learn>=0.20.2->pyannote.audio) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from soundfile>=0.10.2->pyannote.audio) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->pyannote.audio) (2.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from sympy>=1.1->pyannote.metrics>=2.3->pyannote.audio) (1.2.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (1.28.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (1.32.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (3.15.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard>=2.0.0->pyannote.audio) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.0.0->pyannote.audio) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.0.0->pyannote.audio) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.0.0->pyannote.audio) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.8.0->pyannote.audio) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.8.0->pyannote.audio) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.8.0->pyannote.audio) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.8.0->pyannote.audio) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->pyannote.audio) (3.1.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio) (7.1.2)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio) (0.4.4)\n",
      "Requirement already satisfied: Mako in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.1.4)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.0.4)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (20.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from Mako->alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio) (1.1.1)\n",
      "Building wheels for collected packages: audioread, pescador, resampy, pyperclip\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23141 sha256=b33542ffd35cbdca3529f78de4307193e921c9348be0c6da000e47862657469c\n",
      "  Stored in directory: /Users/jauffret/Library/Caches/pip/wheels/49/5a/e4/df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\n",
      "  Building wheel for pescador (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pescador: filename=pescador-2.1.0-py3-none-any.whl size=21076 sha256=6acc19fa00b00b287937d9ef7145941a8b258584f1aaf62becbf2f97b2a26287\n",
      "  Stored in directory: /Users/jauffret/Library/Caches/pip/wheels/04/04/bb/78c0daaafa679c767a2c5be25e36390f33ffecad7aee7ad10e\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320718 sha256=4f5596a50a2b2ed617ce700c9abf716acbe8edcce3d0d56227b3ead123cfe135\n",
      "  Stored in directory: /Users/jauffret/Library/Caches/pip/wheels/6f/d1/5d/f13da53b1dcbc2624ff548456c9ffb526c914f53c12c318bb4\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=debf4da60fd86e67c11ea856af50539d6b89d0f3dc788da95e7a19257eec79d9\n",
      "  Stored in directory: /Users/jauffret/Library/Caches/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully built audioread pescador resampy pyperclip\n",
      "Installing collected packages: pyperclip, pbr, stevedore, PrettyTable, llvmlite, cmd2, numba, colorlog, cmaes, cliff, resampy, pooch, optuna, filelock, audioread, sortedcollections, pyannote.pipeline, pescador, librosa, pyannote.audio\n",
      "Successfully installed PrettyTable-2.1.0 audioread-2.1.9 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorlog-5.0.1 filelock-3.0.12 librosa-0.8.1 llvmlite-0.36.0 numba-0.53.1 optuna-2.7.0 pbr-5.6.0 pescador-2.1.0 pooch-1.3.0 pyannote.audio-1.1.2 pyannote.pipeline-1.5.2 pyperclip-1.8.2 resampy-0.2.2 sortedcollections-2.1.0 stevedore-3.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430a1a6",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7f917",
   "metadata": {},
   "source": [
    "![title](https://github.com/pyannote/pyannote-audio/raw/master/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c33eca",
   "metadata": {},
   "source": [
    "# dia_ami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0496396",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ef864",
   "metadata": {},
   "source": [
    "- Model pytorch dia_ami\n",
    "- Train sur le dataset AMI (70h de meetings annotés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8653d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:20:42.184898Z",
     "start_time": "2021-05-26T15:20:42.040062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jauffret/code/MartinJ9678/meetings-speaker-diarization/notebooks/loic\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8f36a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T16:13:34.148711Z",
     "start_time": "2021-05-26T16:13:33.706508Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "/Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/embedding/approaches/arcface_loss.py:170: FutureWarning: The 's' parameter is deprecated in favor of 'scale', and will be removed in a future release\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia_ami');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29261a36",
   "metadata": {},
   "source": [
    "## Test avec Doctolib.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c20375",
   "metadata": {},
   "source": [
    "Fichier audio issu d'une vidéo avec 3 speakers\n",
    "- 2 speakers qui parlent la plupart du temps\n",
    "- 1 speaker qui parle très peu\n",
    "- musique au début\n",
    "- FR 🇫🇷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42124dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:43:06.443134Z",
     "start_time": "2021-05-26T12:40:01.579831Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/doctolib.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec23e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:43:06.457940Z",
     "start_time": "2021-05-26T12:43:06.448189Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/doctolib_ami.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d4dfae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:44:40.838430Z",
     "start_time": "2021-05-26T12:44:40.820118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.4s and t=0.9s.\n",
      "Speaker \"22\" speaks between t=0.9s and t=1.6s.\n",
      "Speaker \"A\" speaks between t=1.6s and t=12.4s.\n",
      "Speaker \"B\" speaks between t=12.4s and t=14.0s.\n",
      "Speaker \"A\" speaks between t=14.0s and t=38.4s.\n",
      "Speaker \"B\" speaks between t=38.4s and t=53.5s.\n",
      "Speaker \"A\" speaks between t=53.5s and t=55.8s.\n",
      "Speaker \"B\" speaks between t=55.8s and t=97.2s.\n",
      "Speaker \"A\" speaks between t=97.2s and t=148.2s.\n",
      "Speaker \"B\" speaks between t=148.2s and t=162.3s.\n",
      "Speaker \"A\" speaks between t=162.3s and t=163.3s.\n",
      "Speaker \"B\" speaks between t=163.3s and t=168.3s.\n",
      "Speaker \"A\" speaks between t=168.3s and t=169.0s.\n",
      "Speaker \"B\" speaks between t=169.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39bf9a",
   "metadata": {},
   "source": [
    "### Remarques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92975f",
   "metadata": {},
   "source": [
    "- Diarization précise\n",
    "- La musique au début est détéctée comme de la SAD 🤔\n",
    "- Speaker 22 🤷🏻‍♂️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d3511",
   "metadata": {},
   "source": [
    "## Test avec martin.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b740c25",
   "metadata": {},
   "source": [
    "- Interview tele \n",
    "- 2 personnes\n",
    "- EN 🇺🇸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd1727b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.784310Z",
     "start_time": "2021-05-26T12:45:08.584426Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization_martin = pipeline({'audio': 'data/martin.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9480e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.793044Z",
     "start_time": "2021-05-26T12:46:44.788674Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin_ami.rttm', 'w') as f:\n",
    "    diarization_martin.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24ffdf2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T12:46:44.798762Z",
     "start_time": "2021-05-26T12:46:44.795318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.0s and t=5.8s.\n",
      "Speaker \"9\" speaks between t=5.8s and t=6.5s.\n",
      "Speaker \"A\" speaks between t=6.5s and t=16.9s.\n",
      "Speaker \"A\" speaks between t=18.3s and t=22.5s.\n",
      "Speaker \"13\" speaks between t=22.5s and t=23.2s.\n",
      "Speaker \"A\" speaks between t=23.2s and t=110.4s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization_martin.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294fc38",
   "metadata": {},
   "source": [
    "# dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463b10a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e870b4a",
   "metadata": {},
   "source": [
    "- Model pytorch dia\n",
    "- Train sur VoxCeleb1.custom.trn ⋃ VoxCeleb2.trn ⋃ DIHARD.custom.tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb9e64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:16:07.936134Z",
     "start_time": "2021-05-26T15:15:54.335328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained pipeline \"dia_dihard\" to \"/Users/jauffret/.pyannote/hub/pipelines/dia_dihard.zip\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec90849aa62047f381c6e39fddee5d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model \"sad_dihard\" to \"/Users/jauffret/.pyannote/hub/models/sad_dihard.zip\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422e859bf7fc432e8651c4329e218707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model \"scd_dihard\" to \"/Users/jauffret/.pyannote/hub/models/scd_dihard.zip\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280e416691a64d1696ab0ab906b31a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/2.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model \"emb_voxceleb\" to \"/Users/jauffret/.pyannote/hub/models/emb_voxceleb.zip\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a1a45d92a4422eb3fead049ed422f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/pretrained.py:156: UserWarning: Model was trained with 4s chunks and is applied on 2s chunks. This might lead to sub-optimal results.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /Users/jauffret/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d9e12",
   "metadata": {},
   "source": [
    "## doctolib.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d6d861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:16:55.261365Z",
     "start_time": "2021-05-26T15:16:13.875324Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-715f7e4e28ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply diarization pipeline on your audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiarization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'data/doctolib.wav'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speaker_diarization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# segmentation into speech turns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mspeech_turns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech_turn_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# some files are only partially annotated and therefore one cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speech_turn_segmentation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# speech regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0msad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech_activity_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mscd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeaker_change_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speech_activity_detection.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0msad_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# if this check has not been done yet, do it once and for all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/wrapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mFrames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# used to \"inherit\" most scorer_ attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# compute features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# basic quality check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/pretrained.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, y, sample_rate)\u001b[0m\n\u001b[1;32m    224\u001b[0m         )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         return self.model_.slide(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/train/model.py\u001b[0m in \u001b[0;36mslide\u001b[0;34m(self, features, sliding_window, batch_size, device, skip_average, postprocess, return_intermediate, progress_hook)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m# FIXME: fix support for return_intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mtfX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_intermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mtfX_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveforms, return_intermediate)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msincnet_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_intermediate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/models/sincnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveforms)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool1d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/models/sincnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveforms)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mband_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mwaveforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/doctolib.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f3764b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:09:43.918404Z",
     "start_time": "2021-05-26T13:09:43.905988Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/doctolib.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a7c67b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:09:43.925574Z",
     "start_time": "2021-05-26T13:09:43.920732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"A\" speaks between t=0.6s and t=0.8s.\n",
      "Speaker \"B\" speaks between t=1.0s and t=2.3s.\n",
      "Speaker \"A\" speaks between t=2.3s and t=4.3s.\n",
      "Speaker \"A\" speaks between t=4.8s and t=5.3s.\n",
      "Speaker \"A\" speaks between t=5.6s and t=5.8s.\n",
      "Speaker \"A\" speaks between t=6.1s and t=9.8s.\n",
      "Speaker \"A\" speaks between t=10.2s and t=11.6s.\n",
      "Speaker \"A\" speaks between t=11.9s and t=15.5s.\n",
      "Speaker \"A\" speaks between t=15.9s and t=18.8s.\n",
      "Speaker \"A\" speaks between t=19.5s and t=20.4s.\n",
      "Speaker \"A\" speaks between t=20.8s and t=24.6s.\n",
      "Speaker \"A\" speaks between t=24.8s and t=25.1s.\n",
      "Speaker \"A\" speaks between t=25.3s and t=31.0s.\n",
      "Speaker \"A\" speaks between t=31.4s and t=34.8s.\n",
      "Speaker \"B\" speaks between t=35.0s and t=39.2s.\n",
      "Speaker \"B\" speaks between t=39.6s and t=46.4s.\n",
      "Speaker \"B\" speaks between t=46.9s and t=49.4s.\n",
      "Speaker \"B\" speaks between t=49.6s and t=52.7s.\n",
      "Speaker \"A\" speaks between t=52.7s and t=54.3s.\n",
      "Speaker \"A\" speaks between t=54.6s and t=55.1s.\n",
      "Speaker \"B\" speaks between t=55.1s and t=56.7s.\n",
      "Speaker \"B\" speaks between t=56.8s and t=59.0s.\n",
      "Speaker \"B\" speaks between t=59.4s and t=65.5s.\n",
      "Speaker \"B\" speaks between t=65.8s and t=71.7s.\n",
      "Speaker \"B\" speaks between t=72.0s and t=73.9s.\n",
      "Speaker \"B\" speaks between t=74.4s and t=78.6s.\n",
      "Speaker \"B\" speaks between t=79.1s and t=83.1s.\n",
      "Speaker \"B\" speaks between t=83.7s and t=84.8s.\n",
      "Speaker \"B\" speaks between t=85.4s and t=91.2s.\n",
      "Speaker \"B\" speaks between t=91.6s and t=95.9s.\n",
      "Speaker \"A\" speaks between t=95.9s and t=100.6s.\n",
      "Speaker \"A\" speaks between t=101.0s and t=105.5s.\n",
      "Speaker \"A\" speaks between t=105.8s and t=107.8s.\n",
      "Speaker \"A\" speaks between t=108.1s and t=108.8s.\n",
      "Speaker \"A\" speaks between t=109.2s and t=117.8s.\n",
      "Speaker \"A\" speaks between t=118.3s and t=122.3s.\n",
      "Speaker \"A\" speaks between t=122.5s and t=125.4s.\n",
      "Speaker \"A\" speaks between t=125.8s and t=129.2s.\n",
      "Speaker \"A\" speaks between t=129.6s and t=132.5s.\n",
      "Speaker \"A\" speaks between t=132.8s and t=147.5s.\n",
      "Speaker \"B\" speaks between t=147.7s and t=154.5s.\n",
      "Speaker \"B\" speaks between t=154.9s and t=157.4s.\n",
      "Speaker \"B\" speaks between t=157.7s and t=178.2s.\n",
      "Speaker \"B\" speaks between t=178.5s and t=179.6s.\n",
      "Speaker \"B\" speaks between t=179.9s and t=181.8s.\n",
      "Speaker \"B\" speaks between t=182.1s and t=184.1s.\n",
      "Speaker \"B\" speaks between t=184.4s and t=189.3s.\n",
      "Speaker \"B\" speaks between t=189.7s and t=193.1s.\n",
      "Speaker \"B\" speaks between t=193.7s and t=194.7s.\n",
      "Speaker \"B\" speaks between t=195.2s and t=200.1s.\n",
      "Speaker \"B\" speaks between t=200.4s and t=206.7s.\n",
      "Speaker \"B\" speaks between t=207.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005113d",
   "metadata": {},
   "source": [
    "## martin.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76275ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:30:17.319714Z",
     "start_time": "2021-05-26T15:29:56.218573Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-34e77318af70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply diarization pipeline on your audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiarization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'data/martin.wav'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speaker_diarization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# segmentation into speech turns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mspeech_turns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech_turn_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# some files are only partially annotated and therefore one cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speech_turn_segmentation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# speech regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0msad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech_activity_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mscd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeaker_change_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/pipeline/speech_activity_detection.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0msad_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# if this check has not been done yet, do it once and for all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/wrapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mFrames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# used to \"inherit\" most scorer_ attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_file)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# compute features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# basic quality check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/features/pretrained.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, y, sample_rate)\u001b[0m\n\u001b[1;32m    224\u001b[0m         )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         return self.model_.slide(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pyannote/audio/train/model.py\u001b[0m in \u001b[0;36mslide\u001b[0;34m(self, features, sliding_window, batch_size, device, skip_average, postprocess, return_intermediate, progress_hook)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mfX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mtX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/pescador/maps.py\u001b[0m in \u001b[0;36mbuffer_stream\u001b[0;34m(stream, buffer_size, partial, axis)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/martin.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5188217a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:16:19.588014Z",
     "start_time": "2021-05-26T13:16:19.570897Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc1a6c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:16:19.598611Z",
     "start_time": "2021-05-26T13:16:19.590285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"B\" speaks between t=0.0s and t=1.1s.\n",
      "Speaker \"B\" speaks between t=1.8s and t=4.3s.\n",
      "Speaker \"B\" speaks between t=4.5s and t=7.1s.\n",
      "Speaker \"B\" speaks between t=7.8s and t=9.1s.\n",
      "Speaker \"B\" speaks between t=9.4s and t=11.0s.\n",
      "Speaker \"B\" speaks between t=11.2s and t=12.9s.\n",
      "Speaker \"B\" speaks between t=13.4s and t=14.6s.\n",
      "Speaker \"B\" speaks between t=15.2s and t=15.6s.\n",
      "Speaker \"B\" speaks between t=16.1s and t=16.5s.\n",
      "Speaker \"B\" speaks between t=18.4s and t=19.5s.\n",
      "Speaker \"B\" speaks between t=20.0s and t=23.7s.\n",
      "Speaker \"A\" speaks between t=24.4s and t=26.6s.\n",
      "Speaker \"A\" speaks between t=27.4s and t=31.4s.\n",
      "Speaker \"B\" speaks between t=31.9s and t=34.3s.\n",
      "Speaker \"B\" speaks between t=34.5s and t=36.7s.\n",
      "Speaker \"B\" speaks between t=37.7s and t=38.6s.\n",
      "Speaker \"A\" speaks between t=38.6s and t=42.4s.\n",
      "Speaker \"A\" speaks between t=42.8s and t=45.0s.\n",
      "Speaker \"A\" speaks between t=46.1s and t=51.0s.\n",
      "Speaker \"A\" speaks between t=51.9s and t=54.9s.\n",
      "Speaker \"A\" speaks between t=55.6s and t=56.5s.\n",
      "Speaker \"A\" speaks between t=57.3s and t=60.7s.\n",
      "Speaker \"A\" speaks between t=61.7s and t=63.2s.\n",
      "Speaker \"A\" speaks between t=63.6s and t=65.3s.\n",
      "Speaker \"A\" speaks between t=65.9s and t=66.9s.\n",
      "Speaker \"A\" speaks between t=67.4s and t=68.1s.\n",
      "Speaker \"A\" speaks between t=69.1s and t=70.8s.\n",
      "Speaker \"A\" speaks between t=71.6s and t=73.0s.\n",
      "Speaker \"A\" speaks between t=74.4s and t=75.6s.\n",
      "Speaker \"A\" speaks between t=76.0s and t=77.2s.\n",
      "Speaker \"B\" speaks between t=77.7s and t=78.6s.\n",
      "Speaker \"A\" speaks between t=79.7s and t=80.0s.\n",
      "Speaker \"A\" speaks between t=80.3s and t=83.5s.\n",
      "Speaker \"A\" speaks between t=83.8s and t=89.1s.\n",
      "Speaker \"A\" speaks between t=89.5s and t=92.7s.\n",
      "Speaker \"B\" speaks between t=92.7s and t=93.3s.\n",
      "Speaker \"A\" speaks between t=93.8s and t=97.7s.\n",
      "Speaker \"A\" speaks between t=98.6s and t=102.8s.\n",
      "Speaker \"A\" speaks between t=103.5s and t=104.1s.\n",
      "Speaker \"A\" speaks between t=104.8s and t=107.4s.\n",
      "Speaker \"A\" speaks between t=108.5s and t=110.1s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfc4e5",
   "metadata": {},
   "source": [
    "### Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1374a582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:57:22.839039Z",
     "start_time": "2021-05-26T15:57:22.835957Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyannote.database.util import load_rttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0da3815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:44:37.576165Z",
     "start_time": "2021-05-26T13:44:37.373725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x1787184f0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = load_rttm('outputs/martin.rttm')\n",
    "pred['<NA>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57461e5",
   "metadata": {},
   "source": [
    "## martin2.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da69a673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T16:17:15.204655Z",
     "start_time": "2021-05-26T16:15:08.080982Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jauffret/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# apply diarization pipeline on your audio file\n",
    "diarization = pipeline({'audio': 'data/martin2.wav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3117bce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T16:26:31.419486Z",
     "start_time": "2021-05-26T16:26:31.288481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jauffret/code/MartinJ9678/meetings-speaker-diarization/notebooks/loic\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd3653ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T16:24:24.127299Z",
     "start_time": "2021-05-26T16:24:24.122111Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk using RTTM format\n",
    "with open('outputs/martin2.rttm', 'w') as f:\n",
    "    diarization.write_rttm(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58fd68a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:30:13.850945Z",
     "start_time": "2021-05-26T13:30:13.842207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker \"B\" speaks between t=0.4s and t=3.1s.\n",
      "Speaker \"B\" speaks between t=3.4s and t=5.5s.\n",
      "Speaker \"B\" speaks between t=5.9s and t=11.6s.\n",
      "Speaker \"A\" speaks between t=11.9s and t=13.7s.\n",
      "Speaker \"A\" speaks between t=14.0s and t=17.6s.\n",
      "Speaker \"B\" speaks between t=18.0s and t=21.0s.\n",
      "Speaker \"A\" speaks between t=21.0s and t=25.4s.\n",
      "Speaker \"A\" speaks between t=25.7s and t=31.2s.\n",
      "Speaker \"B\" speaks between t=31.4s and t=34.3s.\n",
      "Speaker \"B\" speaks between t=34.8s and t=37.4s.\n",
      "Speaker \"A\" speaks between t=37.4s and t=41.3s.\n",
      "Speaker \"A\" speaks between t=41.6s and t=44.4s.\n",
      "Speaker \"B\" speaks between t=44.7s and t=46.7s.\n",
      "Speaker \"B\" speaks between t=47.2s and t=48.3s.\n",
      "Speaker \"B\" speaks between t=48.9s and t=52.4s.\n",
      "Speaker \"A\" speaks between t=52.4s and t=56.1s.\n",
      "Speaker \"B\" speaks between t=56.5s and t=57.7s.\n",
      "Speaker \"A\" speaks between t=58.0s and t=61.7s.\n",
      "Speaker \"B\" speaks between t=62.1s and t=64.8s.\n",
      "Speaker \"B\" speaks between t=65.3s and t=67.4s.\n",
      "Speaker \"A\" speaks between t=67.7s and t=69.6s.\n",
      "Speaker \"A\" speaks between t=69.9s and t=73.6s.\n",
      "Speaker \"B\" speaks between t=74.0s and t=75.7s.\n",
      "Speaker \"B\" speaks between t=76.0s and t=78.0s.\n",
      "Speaker \"A\" speaks between t=78.4s and t=83.1s.\n",
      "Speaker \"A\" speaks between t=83.4s and t=84.4s.\n",
      "Speaker \"B\" speaks between t=84.7s and t=86.3s.\n",
      "Speaker \"B\" speaks between t=86.5s and t=89.8s.\n",
      "Speaker \"A\" speaks between t=89.8s and t=92.6s.\n",
      "Speaker \"A\" speaks between t=93.0s and t=95.6s.\n",
      "Speaker \"B\" speaks between t=95.9s and t=98.6s.\n",
      "Speaker \"A\" speaks between t=98.6s and t=104.3s.\n",
      "Speaker \"A\" speaks between t=104.6s and t=107.9s.\n",
      "Speaker \"B\" speaks between t=107.9s and t=110.5s.\n",
      "Speaker \"A\" speaks between t=110.7s and t=112.1s.\n",
      "Speaker \"A\" speaks between t=112.4s and t=114.4s.\n",
      "Speaker \"A\" speaks between t=114.8s and t=116.2s.\n",
      "Speaker \"B\" speaks between t=116.7s and t=119.0s.\n",
      "Speaker \"A\" speaks between t=119.4s and t=122.7s.\n",
      "Speaker \"A\" speaks between t=123.0s and t=124.2s.\n",
      "Speaker \"A\" speaks between t=124.4s and t=125.1s.\n",
      "Speaker \"A\" speaks between t=125.3s and t=127.2s.\n",
      "Speaker \"B\" speaks between t=127.6s and t=130.8s.\n",
      "Speaker \"B\" speaks between t=131.1s and t=133.0s.\n",
      "Speaker \"A\" speaks between t=133.4s and t=136.7s.\n",
      "Speaker \"B\" speaks between t=137.0s and t=141.5s.\n",
      "Speaker \"A\" speaks between t=141.8s and t=144.3s.\n",
      "Speaker \"B\" speaks between t=145.1s and t=149.9s.\n",
      "Speaker \"B\" speaks between t=150.4s and t=151.7s.\n",
      "Speaker \"A\" speaks between t=152.1s and t=154.2s.\n",
      "Speaker \"A\" speaks between t=154.5s and t=155.1s.\n",
      "Speaker \"B\" speaks between t=155.4s and t=156.9s.\n",
      "Speaker \"A\" speaks between t=157.5s and t=160.5s.\n",
      "Speaker \"B\" speaks between t=160.8s and t=163.1s.\n",
      "Speaker \"A\" speaks between t=163.4s and t=165.3s.\n",
      "Speaker \"A\" speaks between t=165.5s and t=168.6s.\n",
      "Speaker \"B\" speaks between t=168.9s and t=170.7s.\n",
      "Speaker \"A\" speaks between t=170.9s and t=172.4s.\n",
      "Speaker \"B\" speaks between t=172.4s and t=175.0s.\n",
      "Speaker \"A\" speaks between t=175.2s and t=177.0s.\n",
      "Speaker \"A\" speaks between t=177.2s and t=180.1s.\n",
      "Speaker \"A\" speaks between t=180.2s and t=182.9s.\n",
      "Speaker \"A\" speaks between t=183.2s and t=185.4s.\n",
      "Speaker \"B\" speaks between t=185.9s and t=188.4s.\n",
      "Speaker \"A\" speaks between t=188.4s and t=197.4s.\n",
      "Speaker \"A\" speaks between t=197.7s and t=200.1s.\n",
      "Speaker \"B\" speaks between t=200.3s and t=203.7s.\n",
      "Speaker \"A\" speaks between t=203.7s and t=208.1s.\n",
      "Speaker \"A\" speaks between t=208.7s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "# iterate over speech turns\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f'Speaker \"{speaker}\" speaks between t={turn.start:.1f}s and t={turn.end:.1f}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e2e3c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:38:32.589897Z",
     "start_time": "2021-05-26T13:38:32.585753Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyannote.core import Segment, notebook\n",
    "# make notebook visualization zoom on 600s < t < 660s time range\n",
    "EXCERPT = Segment(0, 220)\n",
    "notebook.crop = EXCERPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c41b0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:39:44.715143Z",
     "start_time": "2021-05-26T13:39:44.412251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x1784803a0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth = load_rttm('outputs/groundtruth/martin2_gt.rttm')\n",
    "groundtruth = groundtruth['121-127105']\n",
    "groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e842b869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:40:26.278849Z",
     "start_time": "2021-05-26T13:40:26.209496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false alarm': 3.3459999999999868,\n",
       " 'confusion': 7.154999999999987,\n",
       " 'correct': 178.07800000000003,\n",
       " 'total': 192.75000000000003,\n",
       " 'missed detection': 7.516999999999999,\n",
       " 'diarization error rate': 0.09347859922178972}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "pred = load_rttm('outputs/martin2.rttm')['<NA>']\n",
    "\n",
    "metric = DiarizationErrorRate()\n",
    "der = metric(groundtruth, pred,detailed=True)\n",
    "der"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17706db0",
   "metadata": {},
   "source": [
    "## Speaker activity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3870fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:34:32.587236Z",
     "start_time": "2021-05-26T10:26:08.337265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/loicsaillant/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is speech between t=0.6s and t=0.8s.\n",
      "There is speech between t=1.0s and t=2.3s.\n",
      "There is speech between t=2.3s and t=4.3s.\n",
      "There is speech between t=4.8s and t=5.3s.\n",
      "There is speech between t=5.6s and t=5.8s.\n",
      "There is speech between t=6.1s and t=9.8s.\n",
      "There is speech between t=10.2s and t=11.6s.\n",
      "There is speech between t=11.9s and t=15.5s.\n",
      "There is speech between t=15.9s and t=18.8s.\n",
      "There is speech between t=19.5s and t=20.4s.\n",
      "There is speech between t=20.8s and t=24.6s.\n",
      "There is speech between t=24.8s and t=25.1s.\n",
      "There is speech between t=25.3s and t=31.0s.\n",
      "There is speech between t=31.4s and t=34.8s.\n",
      "There is speech between t=35.0s and t=39.2s.\n",
      "There is speech between t=39.6s and t=46.4s.\n",
      "There is speech between t=46.9s and t=49.4s.\n",
      "There is speech between t=49.6s and t=52.7s.\n",
      "There is speech between t=52.7s and t=54.3s.\n",
      "There is speech between t=54.6s and t=55.1s.\n",
      "There is speech between t=55.1s and t=56.7s.\n",
      "There is speech between t=56.8s and t=59.0s.\n",
      "There is speech between t=59.4s and t=65.5s.\n",
      "There is speech between t=65.8s and t=71.7s.\n",
      "There is speech between t=72.0s and t=73.9s.\n",
      "There is speech between t=74.4s and t=78.6s.\n",
      "There is speech between t=79.1s and t=83.1s.\n",
      "There is speech between t=83.7s and t=84.8s.\n",
      "There is speech between t=85.4s and t=91.2s.\n",
      "There is speech between t=91.6s and t=95.9s.\n",
      "There is speech between t=95.9s and t=100.6s.\n",
      "There is speech between t=101.0s and t=105.5s.\n",
      "There is speech between t=105.8s and t=107.8s.\n",
      "There is speech between t=108.1s and t=108.8s.\n",
      "There is speech between t=109.2s and t=117.8s.\n",
      "There is speech between t=118.3s and t=122.3s.\n",
      "There is speech between t=122.5s and t=125.4s.\n",
      "There is speech between t=125.8s and t=129.2s.\n",
      "There is speech between t=129.6s and t=132.5s.\n",
      "There is speech between t=132.8s and t=147.5s.\n",
      "There is speech between t=147.7s and t=154.5s.\n",
      "There is speech between t=154.9s and t=157.4s.\n",
      "There is speech between t=157.7s and t=178.2s.\n",
      "There is speech between t=178.5s and t=179.6s.\n",
      "There is speech between t=179.9s and t=181.8s.\n",
      "There is speech between t=182.1s and t=184.1s.\n",
      "There is speech between t=184.4s and t=189.3s.\n",
      "There is speech between t=189.7s and t=193.1s.\n",
      "There is speech between t=193.7s and t=194.7s.\n",
      "There is speech between t=195.2s and t=200.1s.\n",
      "There is speech between t=200.4s and t=206.7s.\n",
      "There is speech between t=207.0s and t=208.8s.\n"
     ]
    }
   ],
   "source": [
    "pipeline_sad = torch.hub.load('pyannote/pyannote-audio', 'sad', pipeline=True)\n",
    "\n",
    "# apply speech activity detection pipeline on your audio file\n",
    "speech_activity_detection = pipeline({'audio': 'data/doctolib.wav'})\n",
    "\n",
    "# dump result to disk using RTTM format\n",
    "# with open('/path/to/your/audio.sad.rttm', 'w') as f:\n",
    "#     speech_activity_detection.write_rttm(f)\n",
    "\n",
    "for speech_region in speech_activity_detection.get_timeline():\n",
    "    print(f'There is speech between t={speech_region.start:.1f}s and t={speech_region.end:.1f}s.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
